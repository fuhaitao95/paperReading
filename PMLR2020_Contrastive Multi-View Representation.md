# PMLR2020_Contrastive Multi-View Representation Learning on Graphs

## Abstract

我们介绍了一种自监督方法，通过对比图的不同结构视图来学习节点和图级别的表示。本文发现，与视觉表示学习不同，将视图数增加到两个以上或者对比不同尺度的编码并不能改善性能，而且，最好的性能是通过对比一阶邻居编码和扩散图来取得的。在一个线性评估方案下，我们在8个节点和图分类基准中的8个实现了最新、最先进的自监督学习结果。比如，在Cora (节点)和Reddit-Binary (图)分类基准，我们实现了86.8%和84.5%的准确率，相对于之前的最先进方法相对改进了5.5%和2.4%.当与监督的基准方法相比时，我们的方法在8个中的4个基准数据集上比他们表现好。

## 1. Introduction

图神经网络调和了交互建模中极具表现力的图和具有无与伦比学习表示的能力的深度模型。